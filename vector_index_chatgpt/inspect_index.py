from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings  # Ou HuggingFaceEmbeddings selon le moteur
import os
import json

# === Chemin de l'index
DB_FAISS_PATH = r"C:\Users\rag_personnel\Logs\vector_index_chatgpt"

# === Chargement des embeddings
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",  # ou supprime ce param√®tre si HuggingFace
)

# === Chargement de l'index FAISS
print("üîç Chargement de l'index...")
try:
    index = FAISS.load_local(
        DB_FAISS_PATH,
        embeddings,
        allow_dangerous_deserialization=True
    )
except Exception as e:
    print(f"‚ùå Erreur de chargement : {e}")
    exit()

# === Recherche test
query = "test"
print(f"\nüß™ Requ√™te test : {query}")
docs = index.similarity_search(query, k=3)

if not docs:
    print("‚ö†Ô∏è Aucun document retourn√©.")
else:
    print(f"‚úÖ {len(docs)} document(s) trouv√©s :")
    for doc in docs:
        print("‚Äî" * 50)
        print(f"R√¥le : {doc.metadata.get('role')}")
        print(f"Ligne : {doc.metadata.get('ligne')}")
        print(f"Contenu : {doc.page_content[:120]}...")

# === Lecture des m√©tadonn√©es globales
meta_path = os.path.join(DB_FAISS_PATH, "metadata.json")
if os.path.exists(meta_path):
    with open(meta_path, "r", encoding="utf-8") as f:
        metadata = json.load(f)
        print("\nüìä M√©tadonn√©es de session :")
        print(json.dumps(metadata, indent=2, ensure_ascii=False))
else:
    print("‚ÑπÔ∏è Aucun fichier metadata.json trouv√©.")
